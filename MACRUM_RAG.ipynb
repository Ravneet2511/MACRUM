{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EeekqgKUU3VJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "# HUGGING_FACE_API = userdata.get('HUGGING_FACE_API')\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "PINECONE_API_KEY = userdata.get('PINECONE_API_KEY')\n",
        "# TARGON_API_KEY = userdata.get('TARGON_API_KEY')\n",
        "# TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')\n",
        "# TOGETHER_API_KEY = userdata.get('TOGETHER_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !uv pip install PyPDF2 langchain faiss-cpu tiktoken langchain-community langchain_groq groq llama_index\n",
        "!uv pip install docx2txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DeQjfOwldyK1",
        "outputId": "cc6ee3a1-8908-44d8-c304-c9ec3e68c821"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.11.12 environment at: /usr\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mdocx2txt==0.9                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2m                                                                              \u001b[0m\r\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 94ms\u001b[0m\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/0)                                                   \r\u001b[2K\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\n",
            "\u001b[2mdocx2txt  \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/3.93 KiB                      \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\n",
            "\u001b[2mdocx2txt  \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 3.93 KiB/3.93 KiB                     \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2m\u001b[0m (1/1)                                                                        \r\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 15ms\u001b[0m\u001b[0m\n",
            "░░░░░░░░░░░░░░░░░░░░ [0/0] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/1] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/1] \u001b[2mdocx2txt==0.9                                        \u001b[0m\r\u001b[2K████████████████████ [1/1] \u001b[2mdocx2txt==0.9                                        \u001b[0m\r\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdocx2txt\u001b[0m\u001b[2m==0.9\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "77B7VFUG1rPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "import os\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import faiss\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "# from langchain.chat_models import ChatOpenAI\n",
        "from langchain_groq import ChatGroq\n",
        "from groq import Groq\n",
        "from langchain.document_loaders import TextLoader\n",
        "# from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.readers.file import DocxReader,PptxReader"
      ],
      "metadata": {
        "id": "wdtnkjPfdsmO"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
        "Chat History: {chat_history}\n",
        "Follow Up Input: {question}\n",
        "Standalone question:\"\"\"\n",
        "\n",
        "CUSTOM_QUESTION_PROMPT = PromptTemplate.from_template(custom_template)"
      ],
      "metadata": {
        "id": "7R-MrMdYd_Yv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pdf_text(docs):\n",
        "    text=\"\"\n",
        "    for pdf in docs:\n",
        "        pdf_reader=PdfReader(pdf)\n",
        "        for page in pdf_reader.pages:\n",
        "            text+=page.extract_text()\n",
        "    return text"
      ],
      "metadata": {
        "id": "w6pJl_IYeEC5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_txt_text(files):\n",
        "    text = \"\"\n",
        "    for path in files:\n",
        "        loader = TextLoader(path, encoding=\"utf-8\")\n",
        "        docs = loader.load()  # returns a list of 1‐element Documents\n",
        "        for doc in docs:\n",
        "            text += doc.page_content + \"\\n\"\n",
        "    return text"
      ],
      "metadata": {
        "id": "D8eYoKWe0F6Q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_docx_text(docx_paths):\n",
        "    text = \"\"\n",
        "    for path in docx_paths:\n",
        "        # use DocxReader on each file\n",
        "        reader = DocxReader()\n",
        "        docs = reader.load_data(path)  # pass list of one path\n",
        "        for doc in docs:\n",
        "            text += doc.text + \"\\n\"\n",
        "    return text"
      ],
      "metadata": {
        "id": "fR6Td82l0E0W"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pptx_text(pptx_paths):\n",
        "    text = \"\"\n",
        "    reader = PptxReader()\n",
        "    for path in pptx_paths:\n",
        "        docs = reader.load_data([path])  # pass a list of one .pptx path\n",
        "        for doc in docs:\n",
        "            text += doc.text + \"\\n\"\n",
        "    return text"
      ],
      "metadata": {
        "id": "uzoXZ-fY59hE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting text to chunks\n",
        "def get_chunks(raw_text):\n",
        "    text_splitter=RecursiveCharacterTextSplitter(\n",
        "                                        # separator=\"\\n\",\n",
        "                                        chunk_size=1024,\n",
        "                                        chunk_overlap=200,\n",
        "                                        length_function=len\n",
        "                                        )\n",
        "    chunks=text_splitter.split_text(raw_text)\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "CcFMKJiAeKOw"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using all-MiniLm embeddings model and faiss to get vectorstore\n",
        "def get_vectorstore(chunks):\n",
        "    embeddings=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "                                     model_kwargs={'device':'cpu'})\n",
        "    vectorstore=faiss.FAISS.from_texts(texts=chunks,embedding=embeddings,metadatas=[{\"source\": f\"chunk_{i}\"} for i in range(len(chunks))])\n",
        "    return vectorstore"
      ],
      "metadata": {
        "id": "iH7opW_KeL3e"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_conversation_chain(vectorstore):\n",
        "    llm=ChatGroq(\n",
        "        api_key=GROQ_API_KEY,\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        temperature=0.4,\n",
        "        max_tokens=1024,\n",
        "    )\n",
        "    memory = ConversationBufferMemory(memory_key='chat_history',\n",
        "                                      return_messages=True,\n",
        "                                      output_key='answer') # using conversation buffer memory to hold past information\n",
        "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
        "                                llm=llm,\n",
        "                                retriever=vectorstore.as_retriever(),\n",
        "                                condense_question_prompt=CUSTOM_QUESTION_PROMPT,\n",
        "                                memory=memory,\n",
        "                                return_source_documents=True\n",
        "                                )\n",
        "    return conversation_chain"
      ],
      "metadata": {
        "id": "chkl6sSteM7g"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_uploaded_filepaths(upload_dir=\"/content\"):\n",
        "    # Get all file paths in the upload directory\n",
        "    return [os.path.join(upload_dir, f) for f in os.listdir(upload_dir) if os.path.isfile(os.path.join(upload_dir, f))]"
      ],
      "metadata": {
        "id": "S37tzGya-lU_"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"Scanning uploaded files in /content ...\")\n",
        "    raw = \"\"\n",
        "\n",
        "    filepaths = get_all_uploaded_filepaths()\n",
        "\n",
        "    for filepath in filepaths:\n",
        "        ext = os.path.splitext(filepath)[1].lower()\n",
        "\n",
        "        try:\n",
        "            if ext == \".pdf\":\n",
        "                print(f\"Processing PDF: {filepath}\")\n",
        "                raw += get_pdf_text([filepath])\n",
        "            elif ext == \".txt\":\n",
        "                print(f\"Processing TXT: {filepath}\")\n",
        "                raw += get_txt_text([filepath])\n",
        "            elif ext == \".docx\":\n",
        "                print(f\"Processing DOCX: {filepath}\")\n",
        "                raw += get_docx_text([filepath])\n",
        "            elif ext == \".pptx\":\n",
        "                print(f\"Processing PPTX: {filepath}\")\n",
        "                raw += get_pptx_text([filepath])\n",
        "            else:\n",
        "                print(f\"Skipping unsupported file: {filepath}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filepath}: {e}\")\n",
        "\n",
        "    if not raw.strip():\n",
        "        print(\"No valid documents found. Exiting.\")\n",
        "        return\n",
        "\n",
        "    chunks = get_chunks(raw)\n",
        "    vectorstore = get_vectorstore(chunks)\n",
        "    # use the same name here as in the loop below:\n",
        "    conversation_chain = get_conversation_chain(vectorstore)\n",
        "\n",
        "    print(\"\\nDocument processing complete. Ask your questions below. Type 'bye' to exit.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "\n",
        "        if user_input.lower() in [\"bye\", \"exit\", \"quit\"]:\n",
        "            print(\"Session ended. Have a great day!\")\n",
        "            break\n",
        "\n",
        "        # Call the correct variable\n",
        "        result = conversation_chain({\"question\": user_input})\n",
        "        answer = result[\"answer\"]\n",
        "        source_docs = result.get(\"source_documents\", [])\n",
        "\n",
        "        # Filter only docs that actually have your metadata key\n",
        "        valid_sources = [\n",
        "            doc for doc in source_docs\n",
        "            if doc.metadata and doc.metadata.get(\"source_file\")\n",
        "        ]\n",
        "\n",
        "        # Print the answer\n",
        "        print(\"AI:\", answer)\n",
        "\n",
        "        # Only print the Sources block if there's at least one valid source\n",
        "        if valid_sources:\n",
        "            print(\"\\nSources:\")\n",
        "            for doc in valid_sources:\n",
        "                meta = doc.metadata\n",
        "                print(f\" • {meta['source_file']} (page {meta.get('page', '?')}, chunk #{meta.get('chunk_index', '?')})\")\n",
        "                snippet = doc.page_content.replace(\"\\n\", \" \")[:200]\n",
        "                print(f\"   → “{snippet}…”\")\n"
      ],
      "metadata": {
        "id": "rM5hKTtcfKAs"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoVdsqGygLRe",
        "outputId": "7b7402cc-173a-4190-f2b3-9f8218225303"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning uploaded files in /content ...\n",
            "Processing DOCX: /content/RAVNEET_OCR_Report.docx\n",
            "Processing PPTX: /content/Smart Credit Risk Assessment Leveraging Data and Machine Intelligence.pptx\n",
            "Error processing /content/Smart Credit Risk Assessment Leveraging Data and Machine Intelligence.pptx: Please install extra dependencies that are required for the PptxReader: `pip install torch transformers python-pptx Pillow`\n",
            "Processing TXT: /content/ABSTRACT.txt\n",
            "Processing PDF: /content/Smart Credit Risk Assessment DRAFT REVISED FINAL (1).pdf\n",
            "\n",
            "Document processing complete. Ask your questions below. Type 'bye' to exit.\n",
            "\n",
            "You: what is this pdf about\n",
            "AI: This PDF appears to be about using machine learning models to predict loan defaults and optimize credit risk assessment. It discusses various machine learning algorithms, such as XGBoost, and techniques like hyperparameter tuning and model evaluation. The text also mentions the importance of proper hyperparameter tuning and model evaluation metrics like accuracy and ROC AUC. Additionally, it seems to touch on potential improvements for future work, but the context is not entirely clear as it mentions \"synthetic fonts\" and \"handwritten examples\", which might be unrelated to the main topic of loan default prediction.\n",
            "You: describe more about\n",
            "AI: The text appears to be a snippet from a research paper or academic document, likely in the field of machine learning and finance. The paper discusses the use of machine learning algorithms, specifically Boosting and XGBoost, to predict loan approval and assess credit risk.\n",
            "\n",
            "The modeling process involved integrating each algorithm into a pipeline and using resampled data for training. The authors used RandomizedSearchCV to perform hyperparameter optimization, which allows for efficient exploration of the parameter space.\n",
            "\n",
            "The paper evaluates the performance of each model using accuracy and ROC AUC (Receiver Operating Characteristic Area Under the Curve) on test data. The results are not provided in the snippet, but the authors suggest that proper hyperparameter tuning is essential for achieving optimal model configurations and better performance.\n",
            "\n",
            "The paper also mentions potential improvements for future work, including training the models for longer periods, using data augmentation, and implementing curriculum learning.\n",
            "\n",
            "The context suggests that the paper is focused on developing a data-driven approach to optimize credit risk assessment in the financial sector, with the goal of supporting better lending choices. The references provided are from various conferences and papers related to machine learning, loan approval, and credit risk prediction.\n",
            "\n",
            "However, without the full paper, it's difficult to provide more detailed information about the specific methods, results, and conclusions.\n",
            "You: thank you bye\n",
            "AI: You're right, there is no question to answer. It seems like the conversation has come to a close. If you have any other questions or need assistance in the future, feel free to ask. Goodbye!\n",
            "You: bye\n",
            "Session ended. Have a great day!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cFG86vHJ-j8d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}